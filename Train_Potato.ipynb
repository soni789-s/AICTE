{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current_dir c:\\Users\\udaya\\OneDrive\\Desktop\\Potato_Disease_Prediction\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print(\"Current_dir\",os.getcwd())\n",
    "path = os.getcwd()\n",
    "train_path = os.path.join(path,\"datasets\",\"Train\")\n",
    "test_path = os.path.join(path,\"datasets\",\"Test\")\n",
    "valid_path = os.path.join(path,\"datasets\",\"Valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 24.0 from c:\\Users\\udaya\\anaconda3\\Lib\\site-packages\\pip (python 3.12)\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip --version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 900 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    pad_to_aspect_ratio=False,\n",
    "    data_format=None,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    valid_path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    pad_to_aspect_ratio=False,\n",
    "    data_format=None,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3,padding='same',activation='relu',input_shape =[128,128,3]))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides =2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters = 64,kernel_size = 3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides =2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters = 128,kernel_size = 3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters =128 ,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides =2))\n",
    "        \n",
    "cnn.add(tf.keras.layers.Conv2D(filters = 256,kernel_size = 3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides =2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters = 512,kernel_size = 3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides =2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(units=1500,activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.001,  # Minimum improvement required\n",
    "    patience=3,       # Wait 5 epochs before stopping\n",
    "    verbose=1,        # Print messages\n",
    "    mode=\"min\",       # Minimize val_loss\n",
    "    restore_best_weights=True  # Restore best weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.4147 - loss: 1.3102 - val_accuracy: 0.7467 - val_loss: 0.6498\n",
      "Epoch 2/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.6851 - loss: 0.6678 - val_accuracy: 0.7733 - val_loss: 0.4849\n",
      "Epoch 3/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.8177 - loss: 0.3921 - val_accuracy: 0.6467 - val_loss: 1.0946\n",
      "Epoch 4/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.8164 - loss: 0.5324 - val_accuracy: 0.8567 - val_loss: 0.2981\n",
      "Epoch 5/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.8458 - loss: 0.3523 - val_accuracy: 0.8867 - val_loss: 0.2572\n",
      "Epoch 6/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.8954 - loss: 0.2267 - val_accuracy: 0.8800 - val_loss: 0.2850\n",
      "Epoch 7/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.8972 - loss: 0.2420 - val_accuracy: 0.8833 - val_loss: 0.2789\n",
      "Epoch 8/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 993ms/step - accuracy: 0.9003 - loss: 0.2410 - val_accuracy: 0.9633 - val_loss: 0.1478\n",
      "Epoch 9/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 982ms/step - accuracy: 0.9503 - loss: 0.1110 - val_accuracy: 0.9367 - val_loss: 0.1427\n",
      "Epoch 10/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 930ms/step - accuracy: 0.9794 - loss: 0.0615 - val_accuracy: 0.9733 - val_loss: 0.1000\n",
      "Epoch 11/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 943ms/step - accuracy: 0.9692 - loss: 0.0733 - val_accuracy: 0.9600 - val_loss: 0.1228\n",
      "Epoch 12/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 977ms/step - accuracy: 0.9785 - loss: 0.0801 - val_accuracy: 0.9167 - val_loss: 0.3113\n",
      "Epoch 13/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 987ms/step - accuracy: 0.9521 - loss: 0.1473 - val_accuracy: 0.9667 - val_loss: 0.0879\n",
      "Epoch 14/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 984ms/step - accuracy: 0.9850 - loss: 0.0309 - val_accuracy: 0.9567 - val_loss: 0.1153\n",
      "Epoch 15/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.9989 - loss: 0.0115 - val_accuracy: 0.8733 - val_loss: 0.5195\n",
      "Epoch 16/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.8475 - loss: 0.3547 - val_accuracy: 0.8833 - val_loss: 0.2849\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n"
     ]
    }
   ],
   "source": [
    "training_history = cnn.fit(x=training_set,validation_data=validation_set,epochs=50,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.9909 - loss: 0.0195\n",
      "0.9900000095367432\n"
     ]
    }
   ],
   "source": [
    "_,train_acc=cnn.evaluate(training_set)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - accuracy: 0.9612 - loss: 0.0966\n",
      "0.9666666388511658\n"
     ]
    }
   ],
   "source": [
    "_,valid_acc=cnn.evaluate(validation_set)\n",
    "print(valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save(\"Train_potato_saved.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
